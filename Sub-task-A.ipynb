{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vU__bqJCztJ"
   },
   "source": [
    "# CS779 Final Evaluation pipeline Task-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-mzYjJn8fTM"
   },
   "source": [
    "# CODALAB submission 4 for scibert+bi-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHMH-IwL5AEg",
    "outputId": "19d23858-f257-48fc-ae4d-0860cb728c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl2DhfLynk4t"
   },
   "source": [
    "# Training Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHn2zthZneJZ",
    "outputId": "56f7d5a0-1928-4dc9-a6b7-358efe00521e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/train'...\n",
      "remote: Enumerating objects: 3083, done.\u001b[K\n",
      "remote: Counting objects: 100% (3083/3083), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2728/2728), done.\u001b[K\n",
      "remote: Total 6864 (delta 567), reused 2504 (delta 279), pack-reused 3781\u001b[K\n",
      "Receiving objects: 100% (6864/6864), 157.36 MiB | 39.88 MiB/s, done.\n",
      "Resolving deltas: 100% (660/660), done.\n",
      "Checking out files: 100% (3286/3286), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ncg-task/training-data.git \"/content/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulLvgGfaneMU",
    "outputId": "8c17d8f4-2e93-4302-c750-6de50772f84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/valid'...\n",
      "remote: Enumerating objects: 1636, done.\u001b[K\n",
      "remote: Counting objects: 100% (1636/1636), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1438/1438), done.\u001b[K\n",
      "remote: Total 1636 (delta 580), reused 1224 (delta 170), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (1636/1636), 27.88 MiB | 39.00 MiB/s, done.\n",
      "Resolving deltas: 100% (580/580), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ncg-task/trial-data.git \"/content/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQUoQVxUneQV",
    "outputId": "b1aeb22c-2bf0-4c42-9f99-5cf97b1b5ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed query_wellformedness 1\n",
      "completed passage_re-ranking 2\n",
      "completed part-of-speech_tagging 8\n",
      "completed sentence_compression 4\n",
      "completed sentiment_analysis 52\n",
      "completed temporal_information_extraction 2\n",
      "completed phrase_grounding 1\n",
      "completed text_generation 6\n",
      "completed text-to-speech_synthesis 3\n",
      "completed smile_recognition 1\n",
      "completed topic_models 1\n",
      "completed question_generation 2\n",
      "completed relation_extraction 14\n",
      "completed paraphrase_generation 2\n",
      "completed question_similarity 1\n",
      "completed question_answering 6\n",
      "completed sentence_classification 3\n",
      "completed prosody_prediction 1\n",
      "completed semantic_role_labeling 5\n",
      "completed text_summarization 15\n",
      "completed semantic_parsing 3\n",
      "completed sarcasm_detection 2\n",
      "completed natural_language_inference 101\n",
      "completed negation_scope_resolution 1\n"
     ]
    }
   ],
   "source": [
    "####Loading Training Data\n",
    "#input_dir = \"/content/drive/My Drive/Train v2/\"\n",
    "input_dir = \"/content/train/\"\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "#list_of_folders = [\"machine-translation\", \"named-entity-recognition\", \"question-answering\",\n",
    "#                   \"relation-classification\",\"text-classification\"]\n",
    "list_of_folders = [\"query_wellformedness\", \"passage_re-ranking\", \"part-of-speech_tagging\", \n",
    "         \"sentence_compression\", \"sentiment_analysis\", \"temporal_information_extraction\", \n",
    "         \"phrase_grounding\", \"text_generation\", \"text-to-speech_synthesis\", \n",
    "         \"smile_recognition\", \"topic_models\", \"question_generation\", \n",
    "         \"relation_extraction\", \"paraphrase_generation\", \"question_similarity\", \n",
    "         \"question_answering\", \"sentence_classification\", \"prosody_prediction\", \n",
    "         \"semantic_role_labeling\", \"text_summarization\", \"semantic_parsing\",\n",
    "         \"sarcasm_detection\", \"natural_language_inference\", \"negation_scope_resolution\"]\n",
    "input_stanza_list = []\n",
    "input_stanza_len = []\n",
    "input_sent_num_list = []\n",
    "file_name_list = []\n",
    "for fls in list_of_folders:\n",
    "  count=0\n",
    "  for i in os.listdir(input_dir + fls + '/'):\n",
    "    count=count+1\n",
    "    for files in os.listdir(input_dir + fls + '/' + str(i)):\n",
    "      if files.endswith(\"Stanza-out.txt\"):\n",
    "        stanza_file = open(input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "        stanza_lines = stanza_file.read()\n",
    "        stanza_lines_list = list(filter(None,map(lambda x:x.lower(),stanza_lines.splitlines()))) # filter empty strings and split into lines\n",
    "        input_stanza_len.append(len(stanza_lines_list))\n",
    "        input_stanza_list.append(stanza_lines_list)\n",
    "      if files.endswith(\"sentences.txt\"):\n",
    "        sentence_file = open(input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "        sentence_num_list = list(filter(None,sentence_file.read().splitlines())) # filter empty strings and split into lines\n",
    "        input_sent_num_list.append(sentence_num_list)\n",
    "    file_name_list.append(fls + '/' + str(i))\n",
    "  print(\"completed\",fls, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiHCPzo9neTj",
    "outputId": "44838fef-3385-4b7a-8607-925bd9a81a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed machine-translation 10\n",
      "completed named-entity-recognition 10\n",
      "completed question-answering 10\n",
      "completed relation-classification 10\n",
      "completed text-classification 10\n"
     ]
    }
   ],
   "source": [
    "##### Validation Dataset Loading\n",
    "#val_input_dir = \"/content/drive/My Drive/Dev_v2/\"\n",
    "val_input_dir = \"/content/valid/\"\n",
    "val_list_of_folders = [\"machine-translation\", \"named-entity-recognition\", \"question-answering\",\n",
    "         \"relation-classification\", \"text-classification\"]\n",
    "val_input_stanza_list = []\n",
    "val_input_sent_num_list = []\n",
    "val_file_name_list = []\n",
    "val_input_stanza_len = []\n",
    "for fls in val_list_of_folders:\n",
    "  count=0\n",
    "  for i in os.listdir(val_input_dir + fls + '/'):\n",
    "    count=count+1\n",
    "    for files in os.listdir(val_input_dir + fls + '/' + str(i)):\n",
    "      if files.endswith(\"Stanza-out.txt\"):\n",
    "        stanza_file = open(val_input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "        stanza_lines = stanza_file.read()\n",
    "        stanza_lines_list = list(filter(None, map(lambda x:x.lower(),stanza_lines.splitlines()))) # filter empty strings and split into lines\n",
    "        val_input_stanza_len.append(len(stanza_lines_list))\n",
    "        val_input_stanza_list.append(stanza_lines_list)\n",
    "      if files.endswith(\"sentences.txt\"):\n",
    "        sentence_file = open(val_input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "        sentence_num_list = list(filter(None,sentence_file.read().splitlines())) # filter empty strings and split into lines\n",
    "        val_input_sent_num_list.append(sentence_num_list)\n",
    "    val_file_name_list.append(fls + '/' + str(i))\n",
    "  print(\"completed\",fls,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "id": "4sXzfj01neWj",
    "outputId": "eff95ed8-a0d2-4a53-9b66-a6dcc8b8c354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train no. of examples for each stanza,sentences and entities\n",
      "237 237 237 237\n",
      "print one example to show all files\n",
      "[2, 71, 72, 19, 20, 21, 24, 58, 59, 60] 96 query_wellformedness/0 513\n",
      "Total number of sentences in training set 5064 and examples 237\n",
      "Valid no. of examples for each stanza,sentences and entities\n",
      "50 50 50 50\n",
      "print one example to show all files\n",
      "[32, 33, 130, 131, 2, 4, 129, 9, 25, 26, 27, 28, 29, 30, 31] 143 machine-translation/5 387\n",
      "Total number of sentences in valid set 1029 and examples 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'identifying well - formed natural language questions'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########Check Flag for Train and Validation set\n",
    "print(\"Train no. of examples for each stanza,sentences and entities\")\n",
    "print(len(input_stanza_list),len(input_sent_num_list),len(input_stanza_len),len(file_name_list))\n",
    "input_sent_num_list = [[int(s) for s in sublist] for sublist in input_sent_num_list] # convert sentence list string to integer\n",
    "input_sent_num_list = [list(set(x)) for x in input_sent_num_list]\n",
    "print(\"print one example to show all files\")\n",
    "print(input_sent_num_list[0],len(input_stanza_list[0]),file_name_list[0],max(input_stanza_len))\n",
    "t_sentence = 0\n",
    "for t in range(len(input_sent_num_list)):\n",
    "  t_sentence += len(input_sent_num_list[t])\n",
    "print(f\"Total number of sentences in training set {t_sentence} and examples {len(input_sent_num_list)}\")\n",
    "##########Check validation\n",
    "print(\"Valid no. of examples for each stanza,sentences and entities\")\n",
    "print(len(val_input_stanza_list),len(val_input_sent_num_list),len(val_input_stanza_len),len(val_file_name_list))\n",
    "val_input_sent_num_list = [[int(s) for s in sublist] for sublist in val_input_sent_num_list] # convert sentence list string to integer\n",
    "val_input_sent_num_list = [list(set(x)) for x in val_input_sent_num_list]\n",
    "print(\"print one example to show all files\")\n",
    "print(val_input_sent_num_list[0],len(val_input_stanza_list[0]),val_file_name_list[0],max(val_input_stanza_len))\n",
    "\n",
    "val_t_sentence = 0\n",
    "for i in range(len(val_input_sent_num_list)):\n",
    "  val_t_sentence += len(val_input_sent_num_list[i])\n",
    "print(f\"Total number of sentences in valid set {val_t_sentence} and examples {len(val_input_sent_num_list)}\")\n",
    "input_stanza_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myS8vvMKneYp"
   },
   "outputs": [],
   "source": [
    "###Ground truth label formation for Train and Validation\n",
    "###############Train\n",
    "multihot_input_sent = []\n",
    "for i in range(len(input_stanza_list)):\n",
    "  temp =[0]*input_stanza_len[i]\n",
    "  for j in range(len(input_sent_num_list[i])):\n",
    "    t1 = input_sent_num_list[i][j] -1\n",
    "    temp[t1] = 1\n",
    "  multihot_input_sent.append(temp)\n",
    "#################valid\n",
    "val_multihot_input_sent = []\n",
    "for i in range(len(val_input_stanza_list)):\n",
    "  temp =[0]*val_input_stanza_len[i]\n",
    "  for j in range(len(val_input_sent_num_list[i])):\n",
    "    t1 = val_input_sent_num_list[i][j] -1\n",
    "    temp[t1] = 1\n",
    "  val_multihot_input_sent.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9k8qTCGCnebN"
   },
   "outputs": [],
   "source": [
    "##Function for flattening 2d list\n",
    "from collections import Iterable\n",
    "def flatten(lis):\n",
    "  for item in lis:\n",
    "    if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "      for x in flatten(item):\n",
    "        yield x\n",
    "    else:        \n",
    "      yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yoBDQdi6962t"
   },
   "outputs": [],
   "source": [
    "####### Flatten Train and Validation nested list for sentence and their labels\n",
    "from collections import Counter\n",
    "\n",
    "train_sentences = list(flatten(input_stanza_list))\n",
    "train_label = list(flatten(multihot_input_sent))\n",
    "valid_sentences = list(flatten(val_input_stanza_list))\n",
    "valid_label = list(flatten(val_multihot_input_sent))\n",
    "print(\"train examples\",len(train_sentences),len(train_label))\n",
    "print(\"valid examples\",len(valid_sentences),len(valid_label))\n",
    "train_tuple = list(set((zip(train_sentences,train_label))))\n",
    "train_in_sentences = []\n",
    "train_sent_label = []\n",
    "for stan,lab in train_tuple:\n",
    "  if len(stan) >4:\n",
    "    train_in_sentences.append(stan)\n",
    "    train_sent_label.append(lab)\n",
    "#train_in_sentences, train_sent_label = zip(*train_tuple)\n",
    "valid_tuple = list(set((zip(valid_sentences,valid_label))))\n",
    "valid_in_sentences = []\n",
    "valid_sent_label = []\n",
    "for stan,lab in valid_tuple:\n",
    "  if len(stan) >4:\n",
    "    valid_in_sentences.append(stan)\n",
    "    valid_sent_label.append(lab)\n",
    "#valid_in_sentences, valid_sent_label = zip(*valid_tuple)\n",
    "print(\"train examples\",len(train_in_sentences),len(train_sent_label))\n",
    "print(\"valid examples\",len(valid_in_sentences),len(valid_sent_label))\n",
    "print(\"train count\", Counter(train_sent_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42PQ_sbx-ACJ"
   },
   "outputs": [],
   "source": [
    "###Oversampling of minority class\n",
    "train_tuple = list(set((zip(train_in_sentences,train_sent_label))))\n",
    "train_sum_sent = 5 * [stan for stan,label in train_tuple if label==1]\n",
    "train_nonsum_sent = [stan for stan,label in train_tuple if label==0]\n",
    "print(len(train_sum_sent), len(train_nonsum_sent))\n",
    "train_in_sentences = train_sum_sent + train_nonsum_sent\n",
    "train_sent_label = len(train_sum_sent)*[1] + len(train_nonsum_sent)*[0]\n",
    "print(\"Oversampled train examples\",len(train_in_sentences),len(train_sent_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fbpM2vNnesV",
    "outputId": "a86ccdcf-df50-4a6c-f260-b40d0012ab8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.8MB 21.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.9MB 52.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 890kB 61.3MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPrbiW4Oneva"
   },
   "outputs": [],
   "source": [
    "########### Pre-processing complete for train and valid. \n",
    "########### Start model building\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "seed_val = 66\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLjiB4FUnex2"
   },
   "outputs": [],
   "source": [
    "##### Parameters for the model\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\t\t\t\n",
    "MAX_LEN = 100\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cr6CpIL7ne0B"
   },
   "outputs": [],
   "source": [
    "#### Dataset Loader\n",
    "class Triage(Dataset):\n",
    "    def __init__(self, data_in,data_out, tokenizer, max_len):\n",
    "        self.len = len(data_in)\n",
    "        self.data = data_in\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.label = data_out\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # title = str(self.data.TITLE[index])\n",
    "        # title = \" \".join(title.split())\n",
    "        title = self.data[index]\n",
    "        inputs = self.tokenizer.encode_plus(title,\n",
    "            None,add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_length = True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        lengths = inputs['length']\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'lengths': torch.tensor(lengths, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.label[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "      return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKo03mC5ozYw"
   },
   "outputs": [],
   "source": [
    "#### Train and Validation Loader \n",
    "training_set = Triage(train_in_sentences,train_sent_label, tokenizer, MAX_LEN)\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,'shuffle': True,'num_workers': 0}\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "valid_set = Triage(valid_in_sentences,valid_sent_label, tokenizer, MAX_LEN)\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,'shuffle': True,'num_workers': 0}\n",
    "valid_loader = DataLoader(valid_set, **valid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnNnn2_2-HRn"
   },
   "outputs": [],
   "source": [
    "# Create a SciBERT + Bi-LSTM model for binary classification\n",
    "class SCIBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SCIBERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased',  output_hidden_states=True)\n",
    "        #self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm = torch.nn.LSTM(768, 400, num_layers=2, batch_first = True, bidirectional=True)\n",
    "        self.l2 = torch.nn.Dropout(0.1)\n",
    "        self.l3 = torch.nn.Linear( 800, 400)\n",
    "        self.l4 = torch.nn.Linear(400,100) # check with layer with 30\n",
    "        self.l5 = torch.nn.Linear(100,2)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids, lengths):\n",
    "        encoded_layers = self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)[2]\n",
    "        scibert_hidden_layer = encoded_layers[12]\n",
    "        #bert_hidden_layer = bert_hidden_layer.permute(1, 0, 2)   #permute rotates the tensor. if tensor.shape = 3,4,5  tensor.permute(1,0,2), then tensor,shape= 4,3,5  (batch_size, sequence_length, hidden_size)\n",
    "        enc_hiddens, (last_hidden, last_cell) = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(scibert_hidden_layer, lengths, batch_first=True, enforce_sorted=False)) #enforce_sorted=False  #pack_padded_sequence(data and batch_sizes\n",
    "        output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)  # (batch_size, 2*hidden_size)\n",
    "        output_hidden = self.l2(output_hidden)            # no size change\n",
    "        output_2 = self.l3(output_hidden)\n",
    "        output_2 = torch.nn.ReLU()(output_2)\n",
    "        #output_3 = self.l2(output_2)\n",
    "        output_4 = self.l4(output_2)\n",
    "        #output_4 = torch.nn.ReLU()(output_4)\n",
    "        output_5 = self.l5(output_4)\n",
    "        return output_5\n",
    "\n",
    "model = SCIBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8he3vdL-P3_"
   },
   "outputs": [],
   "source": [
    "#### Optimizer and Loss function\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr=LEARNING_RATE)\n",
    "c_weights = torch.tensor([list(Counter(train_sent_label).values())[0], list(Counter(train_sent_label).values())[1]], dtype=torch.float32).to(device)\n",
    "c_weights = 1.0/(c_weights/c_weights.sum())\n",
    "c_weights = c_weights/c_weights.sum()\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight = c_weights)\n",
    "print(\"class weights\",c_weights)\n",
    "def calcuate_accu(big_idx, targets):\n",
    "  n_correct = torch.sum((big_idx==targets) * (targets==1)).item()\n",
    "  return n_correct\n",
    "def calculate_labels(targets):\n",
    "  return torch.sum(targets==1).item()\n",
    "valid_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rH9RbecozkD"
   },
   "outputs": [],
   "source": [
    "#### Function for training one epoch\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    n_predict = 0\n",
    "    n_ground = 0\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        lengths = data['lengths'].squeeze(1)#.to(device, dtype = torch.long)\n",
    "        #print(\"print length shape\", lengths.shape, ids.shape, token_type_ids.shape)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        outputs = model(ids, mask,token_type_ids, lengths)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "        n_predict +=calculate_labels(big_idx)\n",
    "        n_ground +=calculate_labels(targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%1000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 1000 steps: {loss_step}\")\n",
    "            #print(f\"Training Accuracy per 1000 steps: {accu_step}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    #print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch {epoch}: {epoch_accu} and Loss: {epoch_loss}\")\n",
    "    P = n_correct/n_predict if n_predict else 0.0\n",
    "    R = n_correct/n_ground if n_ground else 0.0\n",
    "    F1 = (2*P*R)/(P+R) if P+R else 0.0\n",
    "    print(f\"Training P and R and F1 Epoch {epoch}: {P},{R}, {F1}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5pK1s_QozqX"
   },
   "outputs": [],
   "source": [
    "#### Function for validation one epoch\n",
    "def valid(epoch,model, valid_loader):\n",
    "    model.eval()\n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    n_correct = 0\n",
    "    n_predict = 0\n",
    "    n_ground = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(valid_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            lengths = data['lengths'].squeeze(1)#.to(device, dtype = torch.long)\n",
    "            #print(\"print length shape\", lengths.shape, ids.shape, token_type_ids.shape)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask,token_type_ids, lengths)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "            \n",
    "            n_predict +=calculate_labels(big_idx)\n",
    "            n_ground +=calculate_labels(targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            # if _%100==0:\n",
    "            #     loss_step = tr_loss/nb_tr_steps\n",
    "            #     accu_step = (n_correct*100)/nb_tr_examples\n",
    "            #     print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "            #     print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    #print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch {epoch}: {epoch_accu} and Loss: {epoch_loss}\")\n",
    "    valid_loss_list.append(epoch_loss)\n",
    "    P = n_correct/n_predict if n_predict else 0.0\n",
    "    R = n_correct/n_ground if n_ground else 0.0\n",
    "    F1 = (2*P*R)/(P+R) if P+R else 0.0\n",
    "    print(f\"Valiadation  P and R and F1 Epoch {epoch}: {P},{R}, {F1}\")\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "royimMAtpjXs"
   },
   "outputs": [],
   "source": [
    "# Training and Validation model.\n",
    "## Save the model\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "    epoch_loss = valid(epoch,model, valid_loader)\n",
    "    #if epoch <= 6:\n",
    "    torch.save(model,f\"/content/drive/MyDrive/task-1-semeval/scibert-classify-mod-T1-{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVld_fAOrf3g"
   },
   "source": [
    "# Evaluation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "92196fc5251a49019b1643ec3a5160b7",
      "205e1b2d66be4464ad3cd1c9b113c4f1",
      "3c29f0a9e08645c398ece3d1e2eaff05",
      "f9d5ec1297404f7ba14d80b6a9244eca",
      "46c72f1180d047d4a22fd8f9d72db879",
      "58454e44439c45daaacceff55e01fa48",
      "baec4fd332004c278db378e59820b218",
      "6a890f727f4c49759fafe67fdcfbce64",
      "49417fa1582045d896b734c1b666ff78",
      "9a7bcd2efee44f98b7cc0ecc1abe5d20",
      "e2b749b459ea4857830dfaedd93c06a1",
      "3e2962e825894306996639987d374b8d",
      "751351a0b9534bf29b2f4b1c33d063b7",
      "daba319487d54ab5ba231b8135ec5c55",
      "429409bd9ee84ab1a93a3cfcbfba1d09",
      "dfe9fb0bf3ff40799e3e8aa3c5ea2f52"
     ]
    },
    "id": "mbDKVBkbpjac",
    "outputId": "07216356-1d02-491c-8efd-1c3b0bb21688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.8MB 19.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 890kB 24.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.9MB 23.4MB/s \n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92196fc5251a49019b1643ec3a5160b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49417fa1582045d896b734c1b666ff78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=227845.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "seed_val = 66\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUKFDi9Yd8pD",
    "outputId": "5fa539ef-2f44-4587-c737-129f3f118550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "db1612f70498458cae52513ae1dc8309",
      "2fda69b114ef4ef09360ddf1c75a09b4",
      "0c2d6a97f4a14322964c19c5c2ce5781",
      "f5fff8f065c94633b5a4c0b0b9f8e8b6",
      "9e7459d34a794aed95649a1624ed8a70",
      "5f4cc82507804362970dc45cf4b661c0",
      "9919a0bff5ac49899c6874d3877ce0d2",
      "e2ebff762211407993f7f13e6d375f6c"
     ]
    },
    "id": "CfFPGGrDcoEs",
    "outputId": "150ca6eb-3f9e-44f1-975c-a6c68dacdb06"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1612f70498458cae52513ae1dc8309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442221694.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SCIBERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(768, 400, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (l2): Dropout(p=0.1, inplace=False)\n",
       "  (l3): Linear(in_features=800, out_features=400, bias=True)\n",
       "  (l4): Linear(in_features=400, out_features=100, bias=True)\n",
       "  (l5): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a SciBERT + Bi-LSTM model for binary classification\n",
    "class SCIBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SCIBERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased',  output_hidden_states=True)\n",
    "        #self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm = torch.nn.LSTM(768, 400, num_layers=2, batch_first = True, bidirectional=True)\n",
    "        self.l2 = torch.nn.Dropout(0.1)\n",
    "        self.l3 = torch.nn.Linear( 800, 400)\n",
    "        self.l4 = torch.nn.Linear(400,100) # check with layer with 30\n",
    "        self.l5 = torch.nn.Linear(100,2)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids, lengths):\n",
    "        encoded_layers = self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)[2]\n",
    "        scibert_hidden_layer = encoded_layers[12]\n",
    "        #bert_hidden_layer = bert_hidden_layer.permute(1, 0, 2)   #permute rotates the tensor. if tensor.shape = 3,4,5  tensor.permute(1,0,2), then tensor,shape= 4,3,5  (batch_size, sequence_length, hidden_size)\n",
    "        enc_hiddens, (last_hidden, last_cell) = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(scibert_hidden_layer, lengths, batch_first=True, enforce_sorted=False)) #enforce_sorted=False  #pack_padded_sequence(data and batch_sizes\n",
    "        output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)  # (batch_size, 2*hidden_size)\n",
    "        output_hidden = self.l2(output_hidden)            # no size change\n",
    "        output_2 = self.l3(output_hidden)\n",
    "        output_2 = torch.nn.ReLU()(output_2)\n",
    "        #output_3 = self.l2(output_2)\n",
    "        output_4 = self.l4(output_2)\n",
    "        #output_4 = torch.nn.ReLU()(output_4)\n",
    "        output_5 = self.l5(output_4)\n",
    "        return output_5\n",
    "\n",
    "model = SCIBERTClass()\n",
    "model.to(device)\n",
    "\n",
    "model = torch.load(\"/content/drive/MyDrive/task-1-semeval/scibert-classify-mod-T1-1.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v21bQkmlcoHt"
   },
   "outputs": [],
   "source": [
    "%rm -r \"/content/drive/MyDrive/submission8/\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/\"\n",
    "output_dir = \"/content/drive/MyDrive/submission8/\"\n",
    "MAX_LEN=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQxQoluMpjgP",
    "outputId": "3ad34f9f-a0ea-4981-e744-eb9e108b9a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/drive/MyDrive/submission8/constituency_parsing': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/coreference_resolution': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/data-to-text_generation': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/dependency_parsing': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/document_classification': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/entity_linking': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/face_alignment': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/face_detection': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/hypernym_discovery': No such file or directory\n",
      "rm: cannot remove '/content/drive/MyDrive/submission8/natural_language_inference': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%rm -r \"/content/drive/MyDrive/submission8/constituency_parsing\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/coreference_resolution\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/data-to-text_generation\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/dependency_parsing\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/document_classification\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/entity_linking\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/face_alignment\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/face_detection\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/hypernym_discovery\"\n",
    "%rm -r \"/content/drive/MyDrive/submission8/natural_language_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hFkW0e_wozwW"
   },
   "outputs": [],
   "source": [
    "%mkdir \"/content/drive/MyDrive/submission8/constituency_parsing\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/coreference_resolution\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/data-to-text_generation\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/dependency_parsing\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/document_classification\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/entity_linking\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/face_alignment\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/face_detection\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/hypernym_discovery\"\n",
    "%mkdir \"/content/drive/MyDrive/submission8/natural_language_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDAV1r54ne28",
    "outputId": "c0f3739c-45de-4614-ad68-a5bad5c92fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/test': No such file or directory\n",
      "Cloning into '/content/test'...\n",
      "remote: Enumerating objects: 490, done.\u001b[K\n",
      "remote: Counting objects: 100% (490/490), done.\u001b[K\n",
      "remote: Compressing objects: 100% (483/483), done.\u001b[K\n",
      "remote: Total 490 (delta 7), reused 488 (delta 5), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (490/490), 2.50 MiB | 21.50 MiB/s, done.\n",
      "Resolving deltas: 100% (7/7), done.\n"
     ]
    }
   ],
   "source": [
    "%rm -r \"/content/test\"\n",
    "#!unzip \"/content/drive/MyDrive/Sem Eval Task 11 Group 7/Dev v2.zip\" -d \"/content/test\"\n",
    "!git clone https://github.com/ncg-task/evaluation-phase1.git \"/content/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NG1NCmiJreGt",
    "outputId": "e86a1830-ee78-486a-f9f4-889cdbb1f0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of file 213 constituency_parsing/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of file 90 constituency_parsing/6\n",
      "size of file 135 constituency_parsing/2\n",
      "size of file 210 constituency_parsing/3\n",
      "size of file 223 constituency_parsing/0\n",
      "size of file 204 constituency_parsing/1\n",
      "size of file 203 constituency_parsing/8\n",
      "size of file 230 constituency_parsing/7\n",
      "size of file 144 constituency_parsing/4\n",
      "completed constituency_parsing 9\n",
      "size of file 235 coreference_resolution/5\n",
      "size of file 127 coreference_resolution/6\n",
      "size of file 150 coreference_resolution/2\n",
      "size of file 134 coreference_resolution/3\n",
      "size of file 256 coreference_resolution/0\n",
      "size of file 147 coreference_resolution/1\n",
      "size of file 248 coreference_resolution/8\n",
      "size of file 129 coreference_resolution/7\n",
      "size of file 118 coreference_resolution/9\n",
      "size of file 240 coreference_resolution/4\n",
      "completed coreference_resolution 10\n",
      "size of file 319 data-to-text_generation/5\n",
      "size of file 179 data-to-text_generation/6\n",
      "size of file 191 data-to-text_generation/2\n",
      "size of file 126 data-to-text_generation/3\n",
      "size of file 274 data-to-text_generation/0\n",
      "size of file 226 data-to-text_generation/1\n",
      "size of file 301 data-to-text_generation/4\n",
      "completed data-to-text_generation 7\n",
      "size of file 285 dependency_parsing/5\n",
      "size of file 114 dependency_parsing/6\n",
      "size of file 216 dependency_parsing/2\n",
      "size of file 260 dependency_parsing/3\n",
      "size of file 170 dependency_parsing/0\n",
      "size of file 313 dependency_parsing/1\n",
      "size of file 237 dependency_parsing/8\n",
      "size of file 103 dependency_parsing/7\n",
      "size of file 235 dependency_parsing/4\n",
      "completed dependency_parsing 9\n",
      "size of file 264 document_classification/5\n",
      "size of file 164 document_classification/10\n",
      "size of file 252 document_classification/6\n",
      "size of file 226 document_classification/18\n",
      "size of file 128 document_classification/2\n",
      "size of file 191 document_classification/3\n",
      "size of file 93 document_classification/0\n",
      "size of file 226 document_classification/13\n",
      "size of file 256 document_classification/14\n",
      "size of file 284 document_classification/1\n",
      "size of file 218 document_classification/16\n",
      "size of file 203 document_classification/15\n",
      "size of file 231 document_classification/17\n",
      "size of file 258 document_classification/8\n",
      "size of file 214 document_classification/20\n",
      "size of file 139 document_classification/7\n",
      "size of file 222 document_classification/12\n",
      "size of file 243 document_classification/9\n",
      "size of file 210 document_classification/11\n",
      "size of file 265 document_classification/4\n",
      "size of file 242 document_classification/19\n",
      "completed document_classification 21\n",
      "size of file 196 entity_linking/5\n",
      "size of file 214 entity_linking/10\n",
      "size of file 269 entity_linking/6\n",
      "size of file 203 entity_linking/2\n",
      "size of file 220 entity_linking/3\n",
      "size of file 257 entity_linking/0\n",
      "size of file 116 entity_linking/13\n",
      "size of file 195 entity_linking/14\n",
      "size of file 127 entity_linking/1\n",
      "size of file 157 entity_linking/16\n",
      "size of file 259 entity_linking/15\n",
      "size of file 202 entity_linking/8\n",
      "size of file 224 entity_linking/7\n",
      "size of file 266 entity_linking/12\n",
      "size of file 271 entity_linking/9\n",
      "size of file 193 entity_linking/11\n",
      "size of file 229 entity_linking/4\n",
      "completed entity_linking 17\n",
      "size of file 285 face_alignment/5\n",
      "size of file 292 face_alignment/10\n",
      "size of file 351 face_alignment/6\n",
      "size of file 243 face_alignment/18\n",
      "size of file 206 face_alignment/2\n",
      "size of file 338 face_alignment/3\n",
      "size of file 237 face_alignment/0\n",
      "size of file 297 face_alignment/13\n",
      "size of file 265 face_alignment/14\n",
      "size of file 219 face_alignment/1\n",
      "size of file 329 face_alignment/16\n",
      "size of file 286 face_alignment/15\n",
      "size of file 279 face_alignment/17\n",
      "size of file 284 face_alignment/8\n",
      "size of file 214 face_alignment/7\n",
      "size of file 271 face_alignment/12\n",
      "size of file 295 face_alignment/9\n",
      "size of file 266 face_alignment/11\n",
      "size of file 211 face_alignment/4\n",
      "completed face_alignment 19\n",
      "size of file 152 face_detection/5\n",
      "size of file 194 face_detection/10\n",
      "size of file 248 face_detection/6\n",
      "size of file 319 face_detection/18\n",
      "size of file 237 face_detection/2\n",
      "size of file 409 face_detection/3\n",
      "size of file 148 face_detection/0\n",
      "size of file 240 face_detection/13\n",
      "size of file 269 face_detection/14\n",
      "size of file 231 face_detection/1\n",
      "size of file 466 face_detection/16\n",
      "size of file 236 face_detection/15\n",
      "size of file 240 face_detection/17\n",
      "size of file 156 face_detection/8\n",
      "size of file 272 face_detection/20\n",
      "size of file 278 face_detection/7\n",
      "size of file 138 face_detection/12\n",
      "size of file 295 face_detection/21\n",
      "size of file 277 face_detection/9\n",
      "size of file 281 face_detection/11\n",
      "size of file 339 face_detection/4\n",
      "size of file 110 face_detection/19\n",
      "completed face_detection 22\n",
      "size of file 188 hypernym_discovery/5\n",
      "size of file 128 hypernym_discovery/6\n",
      "size of file 246 hypernym_discovery/2\n",
      "size of file 169 hypernym_discovery/3\n",
      "size of file 80 hypernym_discovery/0\n",
      "size of file 108 hypernym_discovery/1\n",
      "size of file 66 hypernym_discovery/8\n",
      "size of file 125 hypernym_discovery/7\n",
      "size of file 116 hypernym_discovery/4\n",
      "completed hypernym_discovery 9\n",
      "size of file 254 natural_language_inference/5\n",
      "size of file 108 natural_language_inference/10\n",
      "size of file 213 natural_language_inference/23\n",
      "size of file 220 natural_language_inference/22\n",
      "size of file 138 natural_language_inference/6\n",
      "size of file 224 natural_language_inference/24\n",
      "size of file 201 natural_language_inference/18\n",
      "size of file 153 natural_language_inference/29\n",
      "size of file 285 natural_language_inference/26\n",
      "size of file 137 natural_language_inference/2\n",
      "size of file 216 natural_language_inference/3\n",
      "size of file 175 natural_language_inference/0\n",
      "size of file 192 natural_language_inference/30\n",
      "size of file 257 natural_language_inference/25\n",
      "size of file 274 natural_language_inference/13\n",
      "size of file 201 natural_language_inference/14\n",
      "size of file 244 natural_language_inference/28\n",
      "size of file 341 natural_language_inference/31\n",
      "size of file 148 natural_language_inference/1\n",
      "size of file 240 natural_language_inference/16\n",
      "size of file 232 natural_language_inference/15\n",
      "size of file 404 natural_language_inference/17\n",
      "size of file 120 natural_language_inference/8\n",
      "size of file 152 natural_language_inference/27\n",
      "size of file 306 natural_language_inference/20\n",
      "size of file 230 natural_language_inference/7\n",
      "size of file 205 natural_language_inference/12\n",
      "size of file 221 natural_language_inference/21\n",
      "size of file 65 natural_language_inference/9\n",
      "size of file 248 natural_language_inference/11\n",
      "size of file 195 natural_language_inference/4\n",
      "size of file 160 natural_language_inference/19\n",
      "completed natural_language_inference 32\n"
     ]
    }
   ],
   "source": [
    "#####Testing dataset reading\n",
    "from shutil import copyfile\n",
    "#val_input_dir = \"/content/drive/My Drive/Dev_v2/\"\n",
    "test_input_dir = \"/content/test/\"\n",
    "test_list_of_folders = [\"constituency_parsing\",\"coreference_resolution\",\n",
    "                   \"data-to-text_generation\",\"dependency_parsing\",\n",
    "                   \"document_classification\",\"entity_linking\",\n",
    "                   \"face_alignment\",\"face_detection\", \"hypernym_discovery\",\n",
    "                   \"natural_language_inference\"]\n",
    "test_input_stanza_list = []\n",
    "test_file_name_list = []\n",
    "test_input_stanza_len = []\n",
    "for fls in test_list_of_folders:\n",
    "  count=0\n",
    "  for i in os.listdir(test_input_dir + fls + '/'):\n",
    "    count=count+1\n",
    "    output_info_folder = os.path.join(output_dir,fls,str(i))\n",
    "    os.makedirs(output_info_folder)\n",
    "    for files in os.listdir(test_input_dir + fls + '/' + str(i)):\n",
    "      if files.endswith(\"Grobid-out.txt\"):\n",
    "        copyfile(test_input_dir + fls + '/' + str(i) + '/' + files, output_dir + fls + '/' + str(i) + '/' + files)\n",
    "      if files.endswith(\"Stanza-out.txt\"):\n",
    "        stanza_file = open(test_input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "        #if not os.path.exists(output_info_folder):\n",
    "        copyfile(test_input_dir + fls + '/' + str(i) + '/' + files, output_dir + fls + '/' + str(i) + '/' + files)\n",
    "        #stanza_file = open(test_input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "        stanza_lines = stanza_file.read()\n",
    "        stanza_lines_list = list(filter(None, map(lambda x:x.lower(),stanza_lines.splitlines()))) # filter empty strings and split into lines\n",
    "        test_input_stanza_len.append(len(stanza_lines_list))\n",
    "        test_input_stanza_list.append(stanza_lines_list)\n",
    "      # if files.endswith(\"sentences.txt\"):\n",
    "      #   sentence_file = open(test_input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "      #   sentence_num_list = list(filter(None,sentence_file.read().splitlines())) # filter empty strings and split into lines\n",
    "      #   test_input_sent_num_list.append(sentence_num_list)\n",
    "    ### Embedd function\n",
    "    # sentence_num_list = list(set(sentence_num_list))\n",
    "    # test_sentence_num_list = [int(s) for s in sentence_num_list]\n",
    "    # test_sentence_label =[0]*len(stanza_lines_list)\n",
    "    # for t5 in range(len(test_sentence_num_list)):\n",
    "    #   t6 = test_sentence_num_list[t5] -1\n",
    "    #   test_sentence_label[t6] = 1\n",
    "    print(\"size of file\",len(stanza_lines_list),fls+'/'+str(i))\n",
    "    with torch.no_grad():\n",
    "      output_file=open(os.path.join(output_info_folder, \"sentences.txt\"),\"a\")\n",
    "      if stanza_lines_list[1] != 'abstract':\n",
    "        output_file.write(str(2) +\"\\n\")\n",
    "      for t8 in range(2,len(stanza_lines_list)):\n",
    "        if (stanza_lines_list[t8]=='conclusion') or (stanza_lines_list[t8]=='conclusions'):\n",
    "          break\n",
    "        test_input = tokenizer.encode_plus(stanza_lines_list[t8], None, add_special_tokens=True, \n",
    "                                           max_length= MAX_LEN, pad_to_max_length=True, \n",
    "                                           return_token_type_ids=True, truncation=True, \n",
    "                                           return_length = True, return_tensors=\"pt\")\n",
    "        test_ids = test_input['input_ids'].to(device, dtype = torch.long)\n",
    "        test_mask = test_input['attention_mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = test_input['token_type_ids'].to(device, dtype = torch.long)\n",
    "        lengths = test_input['length']\n",
    "        #print(\"shape\",test_ids.shape, test_mask.shape, test_token_type_ids.shape)\n",
    "        outputs = model(test_ids, test_mask, test_token_type_ids, lengths)\n",
    "        _, output_idx = torch.max(outputs, dim =1)\n",
    "        t_output_class = output_idx.cpu().detach().numpy().tolist()\n",
    "        #print(\"nfslkn\",t_output_class[0],test_sentence_label[t8])\n",
    "        #output_info_folder = os.path.join(output_dir,fls,str(i))\n",
    "        # if not os.path.exists(output_info_folder):\n",
    "        #   os.makedirs(output_info_folder)\n",
    "        #print(\"hbas\",t_output_class[0])\n",
    "        #for t7 in range(len(t_output_class)):\n",
    "          #print(infoname_test_to_idx[t_output_class[t7]])\n",
    "        output_file=open(os.path.join(output_info_folder, \"sentences.txt\"),\"a\")\n",
    "        if t_output_class[0] == 1:\n",
    "          #output_file=open(os.path.join(output_info_folder, \"sentences.txt\"),\"a\")\n",
    "          output_file.write(str(t8+1) +\"\\n\")\n",
    "    ## test data and label completed\n",
    "    ####\n",
    "    test_file_name_list.append(fls + '/' + str(i))\n",
    "  print(\"completed\",fls,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKuOnpkvFGlO",
    "outputId": "32d50ad6-9f53-4c29-a6fc-74697aaa385f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 9 constituency_parsing\n",
      "completed 10 coreference_resolution\n",
      "completed 7 data-to-text_generation\n",
      "completed 9 dependency_parsing\n",
      "completed 21 document_classification\n",
      "completed 17 entity_linking\n",
      "completed 19 face_alignment\n",
      "completed 22 face_detection\n",
      "completed 9 hypernym_discovery\n",
      "completed 32 natural_language_inference\n",
      "evaluation 155\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#####Test model\n",
    "#test_input_dir = \"/content/drive/My Drive/Dev_v2/\"\n",
    "test_input_dir = \"/content/drive/MyDrive/submission6/\"\n",
    "# test_list_of_folders = [\"machine-translation\", \"named-entity-recognition\", \"question-answering\",\n",
    "#          \"relation-classification\", \"text-classification\"]\n",
    "test_list_of_folders = list_of_folders = [\"constituency_parsing\",\"coreference_resolution\",\n",
    "                   \"data-to-text_generation\",\"dependency_parsing\",\n",
    "                   \"document_classification\",\"entity_linking\",\n",
    "                   \"face_alignment\",\"face_detection\", \"hypernym_discovery\",\n",
    "                   \"natural_language_inference\"]\n",
    "test_input_stanza_list = []\n",
    "test_input_sent_num_list = []\n",
    "test_file_name_list = []\n",
    "test_input_entity_list = []\n",
    "c=0\n",
    "for fls in test_list_of_folders:\n",
    "  c1=c1=0\n",
    "  for i in os.listdir(test_input_dir + fls + '/'):\n",
    "    c1=c1+1\n",
    "    c=c+1\n",
    "    for files in os.listdir(test_input_dir + fls + '/' + str(i)):\n",
    "      if files.endswith(\"Stanza-out.txt\"):\n",
    "        stanza_file = open(test_input_dir + fls + '/' + str(i) + '/' + files, \"r\")\n",
    "        stanza_lines = stanza_file.read()\n",
    "        stanza_lines_list = list(filter(None, map(lambda x:x.lower(),stanza_lines.splitlines()))) # filter empty strings and split into lines\n",
    "        test_input_stanza_list.append(stanza_lines_list)\n",
    "    test_file_name_list.append(fls+'/'+str(i))\n",
    "  print('completed',c1,fls)\n",
    "print('evaluation',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19L9R9OcFPQx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbEgx8BoUr4l"
   },
   "source": [
    "#Evaluation Script for Sentences\n",
    "\n",
    "This is the script provided by the organizers for contribution sentences evaluation. The first argument is the path to the folder containing true labels, second argument is the path to the folder containing predicted labels,\n",
    "third argument is the path to the folder where the \"scores.txt\" will be stored.\n",
    "###**IMPORTANT**\n",
    "\n",
    "Please download the evaluation_for_sentence.py file and place it in /content folder and direct it appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgG1qxALreJm"
   },
   "outputs": [],
   "source": [
    "!python3 /content/drive/MyDrive/CS779_All_Subtasks/evaluation_for_sentence.py \"/content/drive/MyDrive/test\" \"/content/drive/MyDrive/result_cs779\" \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YGS8BDNcoKx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn8QN5CrmguA"
   },
   "source": [
    "SENT_f1:0.4393564356435644\n",
    "\n",
    "SENT_precision:0.44823232323232326\n",
    "\n",
    "SENT_recall:0.4308252427184466\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7Xra-7RcoNR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pidMX60EpjdX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLRKTQygreMx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "18/01/21_Task_1_Language Model_bilstm_variationa_all.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c2d6a97f4a14322964c19c5c2ce5781": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f4cc82507804362970dc45cf4b661c0",
      "max": 442221694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e7459d34a794aed95649a1624ed8a70",
      "value": 442221694
     }
    },
    "205e1b2d66be4464ad3cd1c9b113c4f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fda69b114ef4ef09360ddf1c75a09b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c29f0a9e08645c398ece3d1e2eaff05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58454e44439c45daaacceff55e01fa48",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46c72f1180d047d4a22fd8f9d72db879",
      "value": 385
     }
    },
    "3e2962e825894306996639987d374b8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfe9fb0bf3ff40799e3e8aa3c5ea2f52",
      "placeholder": "​",
      "style": "IPY_MODEL_429409bd9ee84ab1a93a3cfcbfba1d09",
      "value": " 228k/228k [00:00&lt;00:00, 1.80MB/s]"
     }
    },
    "429409bd9ee84ab1a93a3cfcbfba1d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46c72f1180d047d4a22fd8f9d72db879": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "49417fa1582045d896b734c1b666ff78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2b749b459ea4857830dfaedd93c06a1",
       "IPY_MODEL_3e2962e825894306996639987d374b8d"
      ],
      "layout": "IPY_MODEL_9a7bcd2efee44f98b7cc0ecc1abe5d20"
     }
    },
    "58454e44439c45daaacceff55e01fa48": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4cc82507804362970dc45cf4b661c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a890f727f4c49759fafe67fdcfbce64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "751351a0b9534bf29b2f4b1c33d063b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "92196fc5251a49019b1643ec3a5160b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c29f0a9e08645c398ece3d1e2eaff05",
       "IPY_MODEL_f9d5ec1297404f7ba14d80b6a9244eca"
      ],
      "layout": "IPY_MODEL_205e1b2d66be4464ad3cd1c9b113c4f1"
     }
    },
    "9919a0bff5ac49899c6874d3877ce0d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a7bcd2efee44f98b7cc0ecc1abe5d20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e7459d34a794aed95649a1624ed8a70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "baec4fd332004c278db378e59820b218": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "daba319487d54ab5ba231b8135ec5c55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db1612f70498458cae52513ae1dc8309": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c2d6a97f4a14322964c19c5c2ce5781",
       "IPY_MODEL_f5fff8f065c94633b5a4c0b0b9f8e8b6"
      ],
      "layout": "IPY_MODEL_2fda69b114ef4ef09360ddf1c75a09b4"
     }
    },
    "dfe9fb0bf3ff40799e3e8aa3c5ea2f52": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2b749b459ea4857830dfaedd93c06a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daba319487d54ab5ba231b8135ec5c55",
      "max": 227845,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_751351a0b9534bf29b2f4b1c33d063b7",
      "value": 227845
     }
    },
    "e2ebff762211407993f7f13e6d375f6c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5fff8f065c94633b5a4c0b0b9f8e8b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2ebff762211407993f7f13e6d375f6c",
      "placeholder": "​",
      "style": "IPY_MODEL_9919a0bff5ac49899c6874d3877ce0d2",
      "value": " 442M/442M [00:07&lt;00:00, 59.0MB/s]"
     }
    },
    "f9d5ec1297404f7ba14d80b6a9244eca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a890f727f4c49759fafe67fdcfbce64",
      "placeholder": "​",
      "style": "IPY_MODEL_baec4fd332004c278db378e59820b218",
      "value": " 385/385 [00:00&lt;00:00, 1.87kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
